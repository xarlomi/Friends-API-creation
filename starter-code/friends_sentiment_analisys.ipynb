{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friends Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "friends_quotes = pd.read_csv(\"friends_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carlotaportillo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#TextBlob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = requests.get(\"http://127.0.0.1:5000/lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_json = quotes.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_friends = pd.DataFrame(to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_friends['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Mom, I don't have a restaurant, I work in a restaurant.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(entering) Hi guys!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey, Pheebs! Hi!</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey. Oh, oh, how'd it go?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um, not so good. He walked me to the subway and said 'We should do this again!'</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>You are, you're welling up.</td>\n",
       "      <td>Ross</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Am not!</td>\n",
       "      <td>Monica</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>You're gonna be an aunt.</td>\n",
       "      <td>Ross</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>(pushes him and starts to cry) Oh shut up!</td>\n",
       "      <td>Monica</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>(on phone) Hi, Mindy. Hi, it-it's Rachel. Yeah, I'm fine. I-I saw Barry today. Oh, yeah, yeah he-he told me. No, no, it's okay. I hope you two are very happy, I really do. Oh, oh, and Mind, y'know, if-if everything works out, and you guys end up getting married and having kids- and everything- I just hope they have his old hairline and your old nose. (Slams the phone down.) (To everyone) Okay, I know it was a cheap shot, but I feel so much better now.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                        line  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                 No Mom, I don't have a restaurant, I work in a restaurant.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                        (entering) Hi guys!   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                           Hey, Pheebs! Hi!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                  Hey. Oh, oh, how'd it go?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                            Um, not so good. He walked me to the subway and said 'We should do this again!'   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "727                                                                                                                                                                                                                                                                                                                                                                                                                                              You are, you're welling up.   \n",
       "728                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Am not!   \n",
       "729                                                                                                                                                                                                                                                                                                                                                                                                                                                 You're gonna be an aunt.   \n",
       "730                                                                                                                                                                                                                                                                                                                                                                                                                               (pushes him and starts to cry) Oh shut up!   \n",
       "731  (on phone) Hi, Mindy. Hi, it-it's Rachel. Yeah, I'm fine. I-I saw Barry today. Oh, yeah, yeah he-he told me. No, no, it's okay. I hope you two are very happy, I really do. Oh, oh, and Mind, y'know, if-if everything works out, and you guys end up getting married and having kids- and everything- I just hope they have his old hairline and your old nose. (Slams the phone down.) (To everyone) Okay, I know it was a cheap shot, but I feel so much better now.   \n",
       "\n",
       "       name    episode  \n",
       "0    Monica  Episode 2  \n",
       "1    Phoebe        3.0  \n",
       "2       All        3.0  \n",
       "3      Ross        3.0  \n",
       "4    Phoebe        3.0  \n",
       "..      ...        ...  \n",
       "727    Ross        2.0  \n",
       "728  Monica        2.0  \n",
       "729    Ross        2.0  \n",
       "730  Monica        2.0  \n",
       "731  Rachel        2.0  \n",
       "\n",
       "[732 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/carlotaportillo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'Mom',\n",
       " 'I',\n",
       " 'don',\n",
       " 't',\n",
       " 'have',\n",
       " 'a',\n",
       " 'restaurant',\n",
       " 'I',\n",
       " 'work',\n",
       " 'in',\n",
       " 'a',\n",
       " 'restaurant']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(df_friends.iloc[0]['line'])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (string):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(string)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[No, Mom, I, don, t, have, a, restaurant, I, work, in, a, restaurant]</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[entering, Hi, guys]</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Hey, Pheebs, Hi]</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hey, Oh, oh, how, d, it, go]</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Um, not, so, good, He, walked, me, to, the, subway, and, said, We, should, do, this, again]</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           line  \\\n",
       "0                         [No, Mom, I, don, t, have, a, restaurant, I, work, in, a, restaurant]   \n",
       "1                                                                          [entering, Hi, guys]   \n",
       "2                                                                             [Hey, Pheebs, Hi]   \n",
       "3                                                                 [Hey, Oh, oh, how, d, it, go]   \n",
       "4  [Um, not, so, good, He, walked, me, to, the, subway, and, said, We, should, do, this, again]   \n",
       "\n",
       "     name    episode  \n",
       "0  Monica  Episode 2  \n",
       "1  Phoebe        3.0  \n",
       "2     All        3.0  \n",
       "3    Ross        3.0  \n",
       "4  Phoebe        3.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends['line'] = df_friends['line'].apply(tokenize)\n",
    "df_friends.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carlotaportillo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Mom I don t have a restaurant I work in a restaurant</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entering Hi guys</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey Pheebs Hi</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey Oh oh how d it go</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um not so good He walked me to the subway and said We should do this again</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         line  \\\n",
       "0                     No Mom I don t have a restaurant I work in a restaurant   \n",
       "1                                                            entering Hi guys   \n",
       "2                                                               Hey Pheebs Hi   \n",
       "3                                                       Hey Oh oh how d it go   \n",
       "4  Um not so good He walked me to the subway and said We should do this again   \n",
       "\n",
       "     name    episode  \n",
       "0  Monica  Episode 2  \n",
       "1  Phoebe        3.0  \n",
       "2     All        3.0  \n",
       "3    Ross        3.0  \n",
       "4  Phoebe        3.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends['line'] = df_friends['line'].apply(lambda x: \" \".join(x))\n",
    "df_friends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_friends.line =df_friends.line.apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[No, Mom, I, don, t, have, a, restaurant, I, work, in, a, restaurant]</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[entering, Hi, guys]</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Hey, Pheebs, Hi]</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hey, Oh, oh, how, d, it, go]</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Um, not, so, good, He, walked, me, to, the, subway, and, said, We, should, do, this, again]</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           line  \\\n",
       "0                         [No, Mom, I, don, t, have, a, restaurant, I, work, in, a, restaurant]   \n",
       "1                                                                          [entering, Hi, guys]   \n",
       "2                                                                             [Hey, Pheebs, Hi]   \n",
       "3                                                                 [Hey, Oh, oh, how, d, it, go]   \n",
       "4  [Um, not, so, good, He, walked, me, to, the, subway, and, said, We, should, do, this, again]   \n",
       "\n",
       "     name    episode  \n",
       "0  Monica  Episode 2  \n",
       "1  Phoebe        3.0  \n",
       "2     All        3.0  \n",
       "3    Ross        3.0  \n",
       "4  Phoebe        3.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Stopping useless words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words (lista):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    nueva_lista = []\n",
    "    for string in lista:\n",
    "        if string not in stop_words:\n",
    "            nueva_lista.append(string)\n",
    "    return \" \".join(nueva_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Mom I restaurant I work restaurant</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entering Hi guys</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey Pheebs Hi</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey Oh oh go</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um good He walked subway said We</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    line    name    episode\n",
       "0  No Mom I restaurant I work restaurant  Monica  Episode 2\n",
       "1                       entering Hi guys  Phoebe        3.0\n",
       "2                          Hey Pheebs Hi     All        3.0\n",
       "3                           Hey Oh oh go    Ross        3.0\n",
       "4       Um good He walked subway said We  Phoebe        3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends.line = df_friends.line.apply(stop_words)\n",
    "df_friends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/carlotaportillo/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(sentence):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    polarity = sia.polarity_scores(sentence)\n",
    "    pol = polarity['compound']\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>name</th>\n",
       "      <th>episode</th>\n",
       "      <th>quotes_sentiment_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Mom I restaurant I work restaurant</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Episode 2</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entering Hi guys</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey Pheebs Hi</td>\n",
       "      <td>All</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey Oh oh go</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Um good He walked subway said We</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    line    name    episode  \\\n",
       "0  No Mom I restaurant I work restaurant  Monica  Episode 2   \n",
       "1                       entering Hi guys  Phoebe        3.0   \n",
       "2                          Hey Pheebs Hi     All        3.0   \n",
       "3                           Hey Oh oh go    Ross        3.0   \n",
       "4       Um good He walked subway said We  Phoebe        3.0   \n",
       "\n",
       "   quotes_sentiment_compound  \n",
       "0                    -0.2960  \n",
       "1                     0.0000  \n",
       "2                     0.0000  \n",
       "3                     0.0000  \n",
       "4                     0.4404  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends['quotes_sentiment_compound'] = df_friends.line.apply(sentimentAnalysis)\n",
    "df_friends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Carol                      -0.047233\n",
       "Paula                      -0.021900\n",
       "Bernice                     0.000000\n",
       "Paolo                       0.040569\n",
       "Robbie                      0.045260\n",
       "Susan                       0.048011\n",
       "Monica                      0.089044\n",
       "Mr. Heckles                 0.108080\n",
       "Lizzie                      0.108445\n",
       "Phoebe                      0.117571\n",
       "Mrs. Geller                 0.119530\n",
       "Joey                        0.145465\n",
       "Ross                        0.167445\n",
       "Marsha                      0.168775\n",
       "All                         0.172123\n",
       "Rachel                      0.172487\n",
       "Barry                       0.178237\n",
       "Chandler                    0.196692\n",
       "The Guys                    0.202300\n",
       "Jill                        0.257069\n",
       "Chandler and Joey           0.296000\n",
       "Mr. Geller                  0.309440\n",
       "Alan                        0.328250\n",
       "Dr. Oberman                 0.389150\n",
       "Monica, Joey, and Phoebe    0.440400\n",
       "Name: quotes_sentiment_compound, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_friends.groupby(\"name\")[\"quotes_sentiment_compound\"].mean(). sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
